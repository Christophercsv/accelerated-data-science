kind: operator
spec:
  output_directory:
    url: ./
  report_file_name: report.html
  test_data:
    url: ~/Downloads/test.csv
  metrics:
    - name: toxicity
      load_args:
        path: toxicity
      compute_args:
        predictions: predictions
      type: huggingface
    - name: toxicity_ratio
      load_args:
        path: toxicity
      compute_args:
        predictions: predictions
        aggregation: ratio
      type: huggingface
    - name: toxicity_maximum
      load_args:
        path: toxicity
      compute_args:
        predictions: predictions
        aggregation: maximum
      type: huggingface
    - name: hurtful_sentence
      load_args:
        path: honest
        config_name: en
      compute_args:
        groups: ["queer", "noqueer"]
      type: huggingface
    - name: language_polarity
      load_args:
        path: regard
        module_type: measurement
      type: huggingface
    - name: CustomMetric
      load_args:
        path: ads/opctl/operator/lowcode/responsible_ai/guardrail/custom_guardrail.py
      type: custom
      class_name: CustomGuardRail
type: responsible_ai
version: v1
