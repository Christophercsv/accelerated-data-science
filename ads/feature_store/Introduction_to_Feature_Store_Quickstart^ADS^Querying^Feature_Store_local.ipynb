{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4a426ee8",
   "metadata": {},
   "source": [
    "@notebook{feature_store-quickstart.ipynb,\n",
    "    title: Using feature store for feature ingestion and feature querying,\n",
    "    summary: Feature store quickstart guide to perform feature ingestion and feature querying.,\n",
    "    developed_on: fs_pyspark32_p38_cpu_v1,\n",
    "    keywords: feature store,\n",
    "    license: Universal Permissive License v 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98a0a2",
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Upgrade Oracle ADS to pick up the latest preview version to maintain compatibility with Oracle Cloud Infrastructure.\n",
    "\n",
    "!odsc conda install --uri https://objectstorage.us-ashburn-1.oraclecloud.com/p/qnzzHQPGQYghdyH206yDk25MZH1FaMGdNNhKUl74BhRsW4muvFyGViKIqpxgnxI3/n/ociodscdev/b/ads_conda_pack_builds/o/PySpark_3/teamcity_20230512_084146_38972446/f227145b7ee5fc1c73a69ebaa671b81e/PySpark_3.2_and_Feature_Store.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dc5be9",
   "metadata": {},
   "source": [
    "Oracle Data Science service sample notebook.\n",
    "\n",
    "Copyright (c) 2022 Oracle, Inc. All rights reserved. Licensed under the [Universal Permissive License v 1.0](https://oss.oracle.com/licenses/upl).\n",
    "\n",
    "***\n",
    "\n",
    "# <font color=\"red\">Feature store quickstart</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=\"teal\">Oracle Cloud Infrastructure Data Science Service.</font></p>\n",
    "\n",
    "---\n",
    "# Overview:\n",
    "---\n",
    "Managing many datasets, data-sources and transformations for machine learning is complex and costly. Poorly cleaned data, data issues, bugs in transformations, data drift and training serving skew all leads to increased model development time and worse model performance. Here, feature store is well positioned to solve many of the problems since it provides a centralised way to transform and access data for training and serving time and helps defines a standardised pipeline for ingestion of data and querying of data.\n",
    "\n",
    "## Contents:\n",
    "\n",
    "- <a href=\"#concepts\">1. Introduction</a>\n",
    "- <a href='#pre-requisites'>2. Pre-requisites</a>\n",
    "    - <a href='#policies'>2.1 Policies</a>\n",
    "    - <a href='#prerequisites_authentication'>2.2 Authentication</a>\n",
    "    - <a href='#prerequisites_variables'>2.3 Variables</a>\n",
    "- <a href='#featurestore_overview'>3. Feature store quickstart using APIs</a>\n",
    "    - <a href='#create_featurestore'>3.1. Create feature store</a>\n",
    "    - <a href='#create_entity'>3.2. Create business entity in feature store</a>\n",
    "    - <a href='#create_featuregroup'>3.3. Create feature group and upload data to feature group</a>\n",
    "    - <a href='#query_featuregroup'>3.4. Query feature group</a>\n",
    "    - <a href='#create_dataset'>3.5. Create dataset from multiple or one feature group</a>\n",
    "    - <a href='#query_dataset'>3.6 Query dataset</a>\n",
    "- <a href='#featurestore_yaml'>4. Feature store quickstart using YAML</a>\n",
    "- <a href='#ref'>5. References</a>\n",
    "\n",
    "---\n",
    "\n",
    "**Important:**\n",
    "\n",
    "Placeholder text for required values are surrounded by angle brackets that must be removed when adding the indicated content. For example, when adding a database name to `database_name = \"<database_name>\"` would become `database_name = \"production\"`.\n",
    "\n",
    "---\n",
    "\n",
    "Datasets are provided as a convenience.  Datasets are considered third-party content and are not considered materials under your agreement with Oracle.\n",
    "\n",
    "This [`Citi Bike`](https://ride.citibikenyc.com/data-sharing-policy) dataset license is used in this notebook.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41663f1",
   "metadata": {},
   "source": [
    "<a id=\"concepts\"></a>\n",
    "# 1. Introduction\n",
    "\n",
    "Oracle feature store is a stack based solution that is deployed in the customer enclave using OCI resource manager. Customer can stand up the service with infrastructure in their own tenancy. The service consists of API which are deployed in customer tenancy using resource manager.\n",
    "\n",
    "The following are some key terms that will help you understand OCI Data Science Feature Store:\n",
    "\n",
    "\n",
    "* **Feature Vector**: Set of feature values for any one primary/identifier key. Eg. All/subset of features of customer id ‘2536’ can be called as one feature vector.\n",
    "\n",
    "* **Feature**: A feature is an individual measurable property or characteristic of a phenomenon being observed.\n",
    "\n",
    "* **Entity**: An entity is a group of semantically related features. The first step a consumer of features would typically do when accessing the feature store service is to list the entities and the entities associated features. Another way to look at it is that an entity is an object or concept that is described by its features. Examples of entities could be customer, product, transaction, review, image, document, etc.\n",
    "\n",
    "* **Feature Group**: A feature group in a feature store is a collection of related features that are often used together in ml models. It serves as an organizational unit within the feature store for users to manage, version and share features across different ml projects. By organizing features into groups, data scientists and ml engineers can efficiently discover, reuse and collaborate on features reducing the redundant work and ensuring consistency in feature engineering.\n",
    "\n",
    "* **Feature Group Job**: Feature group job is the execution instance of a feature group. Each feature group job will include validation results and statistics results.\n",
    "\n",
    "* **Dataset**: A dataset is a collection of feature that are used together to either train a model or perform model inference.\n",
    "\n",
    "* **Dataset Job**: Dataset job is the execution instance of a dataset. Each dataset job will include validation results and statistics results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f00ee",
   "metadata": {},
   "source": [
    "<a id='pre-requisites'></a>\n",
    "# 2. Pre-requisites\n",
    "\n",
    "Notebook Sessions are accessible through the following conda environment: \n",
    "\n",
    "* **PySpark 3.2 and Feature store 1.0 (fs_pyspark32_p38_cpu_v1)**\n",
    "\n",
    "You can customize `fs_pyspark32_p38_cpu_v1`, publish it, and use it as a runtime environment for a Notebook session cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503e105",
   "metadata": {},
   "source": [
    "<a id='setup_spark-defaults'></a>\n",
    "### `spark-defaults.conf`\n",
    "\n",
    "The `spark-defaults.conf` file is used to define the properties that are used by Spark. A templated version is installed when you install a Data Science conda environment that supports PySpark. However, you must update the template so that the Data Catalog metastore can be accessed. You can do this manually. However, the `odsc data-catalog config` commandline tool is ideal for setting up the file because it gathers information about your environment, and uses that to build the file.\n",
    "\n",
    "The `odsc data-catalog config` command line tool needs the `--metastore` option to define the Data Catalog metastore OCID. No other command line option is needed because settings have default values, or they take values from your notebook session environment. Following are common parameters that you may need to override.\n",
    "\n",
    "The `--authentication` option sets the authentication mode. It supports resource principal and API keys. The preferred method for authentication is resource principal, which is sent with `--authentication resource_principal`. If you want to use API keys, then use the `--authentication api_key` option. If the `--authentication` isn't specified, API keys are used. When API keys are used, information from the OCI configuration file is used to create the `spark-defaults.conf` file.\n",
    "\n",
    "Object Storage and Data Catalog are regional services. By default, the region is set to the region your notebook session is running in. This information is taken from the environment variable, `NB_REGION`. Use the `--region` option to override this behavior.\n",
    "\n",
    "The default location of the `spark-defaults.conf` file is `/home/datascience/spark_conf_dir` as defined in the `SPARK_CONF_DIR` environment variable. Use the `--output` option to define the directory where to write the file.\n",
    "\n",
    "You need to determine what settings are appropriate for your configuration. However, the following works for most configurations and is run in a terminal window.\n",
    "\n",
    "```bash\n",
    "odsc data-catalog config --authentication resource_principal --metastore <metastore_id>\n",
    "```\n",
    "For more assistance, use the following command in a terminal window:\n",
    "\n",
    "```bash\n",
    "odsc data-catalog config --help\n",
    "```\n",
    "\n",
    "<a id='setup_session'></a>\n",
    "### Session Setup\n",
    "\n",
    "The notebook makes connections to the Data Catalog metastore and Object Storage. In the next cell, specify the bucket URI to act as the data warehouse. Use the `warehouse_uri` variable with the `oci://<bucket_name>@<namespace_name>/<key>` format. Update the variable `metastore_id` with the OCID of the Data Catalog metastore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a781306",
   "metadata": {},
   "source": [
    "<a id='policies'></a>\n",
    "### 2.1. Policies\n",
    "This section covers the creation of dynamic groups and policies needed to use the service.\n",
    "\n",
    "* [About Data Science Policies](https://docs.oracle.com/iaas/data-science/using/policies.htm)\n",
    "* [Data Catalog Metastore Required Policies](https://docs.oracle.com/en-us/iaas/data-catalog/using/metastore.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7106e4",
   "metadata": {},
   "source": [
    "<a id=\"prerequisites_authentication\"></a>\n",
    "### 2.2. Authentication\n",
    "The [Oracle Accelerated Data Science SDK (ADS)](https://docs.oracle.com/iaas/tools/ads-sdk/latest/index.html) controls the authentication mechanism with the notebook Spark cluster.<br> \n",
    "To setup authentication use the ```ads.set_auth(\"resource_principal\")``` or ```ads.set_auth(\"api_key\")```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "ads.set_auth(auth=\"api_key\", client_kwargs={\"service_endpoint\": \"http://localhost:21000/20230101\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c223c0",
   "metadata": {},
   "source": [
    "<a id=\"prerequisites_variables\"></a>\n",
    "### 2.3. Variables\n",
    "To run this notebook, you must provide some information about your tenancy configuration. To create and run a feature store, you must specify a `<compartment_id>` and bucket `<metastore_id>` for storing logs. The [Data Catalog Hive Metastore](https://docs.oracle.com/en-us/iaas/data-catalog/using/metastore.htm) provides schema definitions for objects in structured and unstructured data assets. The Metastore is the central metadata repository to understand tables backed by files on object storage and the metastore id of hive metastore is tied to feature store construct of feature store service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca06cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "compartment_id = \"ocid1.tenancy.oc1..aaaaaaaa462hfhplpx652b32ix62xrdijppq2c7okwcqjlgrbknhgtj2kofa\"\n",
    "metastore_id = \"ocid1.datacatalogmetastore.oc1.iad.amaaaaaabiudgxyap7tizm4gscwz7amu7dixz7ml3mtesqzzwwg3urvvdgua\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc9e2c",
   "metadata": {},
   "source": [
    "<a id=\"featurestore_overview\"></a>\n",
    "# 3. Feature store quick start using APIs\n",
    "By default the **PySpark 3.2, Feature store and Data Flow** conda environment includes pre-installed [great-expectations](https://legacy.docs.greatexpectations.io/en/latest/reference/core_concepts/validation.html) and [deeque](https://github.com/awslabs/deequ) libraries. In an ADS feature store module, you can either use the Python programmatic or YAML interface to define feature store entities. Below section describes how to create feature store entities using programmatic interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfeace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from ads.feature_store.feature_store import FeatureStore\n",
    "from ads.feature_store.dataset import Dataset\n",
    "from ads.feature_store.feature_group import FeatureGroup\n",
    "from ads.feature_store.feature_store_registrar import FeatureStoreRegistrar\n",
    "from ads.feature_store.common.enums import ExpectationType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3fad36",
   "metadata": {},
   "source": [
    "<a id=\"create_featurestore\"></a>\n",
    "### 3.1 Create feature store\n",
    "Feature store is a top level construct to provide logical segregation of resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4688d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_resource = (\n",
    "    FeatureStore().\n",
    "    with_description(\"Data consisting of bike riders data\").\n",
    "    with_compartment_id(compartment_id).\n",
    "    with_display_name(\"Bike rides\").\n",
    "    with_offline_config(metastore_id=metastore_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "191d1d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store = feature_store_resource.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba52241",
   "metadata": {},
   "source": [
    "<a id=\"create_entity\"></a>\n",
    "### 3.2 Create entity\n",
    "An entity is a group of semantically related features. The first step a consumer of features would typically do when accessing the feature store service is to list the entities and the entities associated features. Another way to look at it is that an entity is an object or concept that is described by its features. Examples of entities could be customer, product, transaction, review, image, document, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3fff48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = feature_store.create_entity(\n",
    "    display_name=\"Bike rides\",\n",
    "    description=\"description for bike riders\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d165b",
   "metadata": {},
   "source": [
    "<a id=\"create_featuregroup\"></a>\n",
    "### 3.3 Create feature group\n",
    "A feature group is the code that contains instructions on the ingestion of raw data and computation of the feature. This [`Citi Bike`](https://ride.citibikenyc.com/data-sharing-policy) dataset license is used in this notebook. values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aaac72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df = pd.read_csv(\"~/Downloads/201901-citibike-tripdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47140320",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df = bike_df.drop(['start station name', 'end station name'], axis=1).head(100)\n",
    "bike_df.columns = bike_df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e87a1587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>startstationid</th>\n",
       "      <th>startstationlatitude</th>\n",
       "      <th>startstationlongitude</th>\n",
       "      <th>endstationid</th>\n",
       "      <th>endstationlatitude</th>\n",
       "      <th>endstationlongitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320</td>\n",
       "      <td>2019-01-01 00:01:47.4010</td>\n",
       "      <td>2019-01-01 00:07:07.5810</td>\n",
       "      <td>3160.0</td>\n",
       "      <td>40.778968</td>\n",
       "      <td>-73.973747</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>40.788221</td>\n",
       "      <td>-73.970416</td>\n",
       "      <td>15839</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316</td>\n",
       "      <td>2019-01-01 00:04:43.7360</td>\n",
       "      <td>2019-01-01 00:10:00.6080</td>\n",
       "      <td>519.0</td>\n",
       "      <td>40.751873</td>\n",
       "      <td>-73.977706</td>\n",
       "      <td>518.0</td>\n",
       "      <td>40.747804</td>\n",
       "      <td>-73.973442</td>\n",
       "      <td>32723</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>591</td>\n",
       "      <td>2019-01-01 00:06:03.9970</td>\n",
       "      <td>2019-01-01 00:15:55.4380</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>40.785247</td>\n",
       "      <td>-73.976673</td>\n",
       "      <td>3154.0</td>\n",
       "      <td>40.773142</td>\n",
       "      <td>-73.958562</td>\n",
       "      <td>27451</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2719</td>\n",
       "      <td>2019-01-01 00:07:03.5450</td>\n",
       "      <td>2019-01-01 00:52:22.6500</td>\n",
       "      <td>504.0</td>\n",
       "      <td>40.732219</td>\n",
       "      <td>-73.981656</td>\n",
       "      <td>3709.0</td>\n",
       "      <td>40.738046</td>\n",
       "      <td>-73.996430</td>\n",
       "      <td>21579</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>303</td>\n",
       "      <td>2019-01-01 00:07:35.9450</td>\n",
       "      <td>2019-01-01 00:12:39.5020</td>\n",
       "      <td>229.0</td>\n",
       "      <td>40.727434</td>\n",
       "      <td>-73.993790</td>\n",
       "      <td>503.0</td>\n",
       "      <td>40.738274</td>\n",
       "      <td>-73.987520</td>\n",
       "      <td>35379</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration                 starttime                  stoptime  \\\n",
       "0           320  2019-01-01 00:01:47.4010  2019-01-01 00:07:07.5810   \n",
       "1           316  2019-01-01 00:04:43.7360  2019-01-01 00:10:00.6080   \n",
       "2           591  2019-01-01 00:06:03.9970  2019-01-01 00:15:55.4380   \n",
       "3          2719  2019-01-01 00:07:03.5450  2019-01-01 00:52:22.6500   \n",
       "4           303  2019-01-01 00:07:35.9450  2019-01-01 00:12:39.5020   \n",
       "\n",
       "   startstationid  startstationlatitude  startstationlongitude  endstationid  \\\n",
       "0          3160.0             40.778968             -73.973747        3283.0   \n",
       "1           519.0             40.751873             -73.977706         518.0   \n",
       "2          3171.0             40.785247             -73.976673        3154.0   \n",
       "3           504.0             40.732219             -73.981656        3709.0   \n",
       "4           229.0             40.727434             -73.993790         503.0   \n",
       "\n",
       "   endstationlatitude  endstationlongitude  bikeid    usertype  birthyear  \\\n",
       "0           40.788221           -73.970416   15839  Subscriber       1971   \n",
       "1           40.747804           -73.973442   32723  Subscriber       1964   \n",
       "2           40.773142           -73.958562   27451  Subscriber       1987   \n",
       "3           40.738046           -73.996430   21579  Subscriber       1990   \n",
       "4           40.738274           -73.987520   35379  Subscriber       1979   \n",
       "\n",
       "   gender  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e704bb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"expectation_type\": \"expect_column_values_to_not_be_null\", \"meta\": {}, \"kwargs\": {\"column\": \"stoptime\"}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from great_expectations.core import ExpectationSuite, ExpectationConfiguration\n",
    "\n",
    "expectation_suite = ExpectationSuite(expectation_suite_name=\"feature_definition\")\n",
    "expectation_suite.add_expectation(\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"stoptime\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02d6fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group_bike = (\n",
    "    FeatureGroup()\n",
    "    .with_feature_store_id(feature_store.id)\n",
    "    .with_primary_keys([\"bikeid\"])\n",
    "    .with_name(\"bike_feature_group\")\n",
    "    .with_entity_id(entity.id)\n",
    "    .with_compartment_id(compartment_id)\n",
    "    .with_schema_details_from_dataframe(bike_df)\n",
    "    .with_expectation_suite(expectation_suite, ExpectationType.LENIENT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "228401d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kind: FeatureGroup\n",
       "spec:\n",
       "  compartmentId: ocid1.tenancy.oc1..aaaaaaaa462hfhplpx652b32ix62xrdijppq2c7okwcqjlgrbknhgtj2kofa\n",
       "  entityId: 1C29D0DF65E456211B7351D85F271E03\n",
       "  expectationDetails:\n",
       "    createRuleDetails:\n",
       "    - arguments:\n",
       "        column: stoptime\n",
       "      levelType: ERROR\n",
       "      name: Rule-0\n",
       "      ruleType: expect_column_values_to_not_be_null\n",
       "    expectationType: LENIENT\n",
       "    name: feature_definition\n",
       "    validationEngineType: GREAT_EXPECTATIONS\n",
       "  featureStoreId: AB5F8E0C4BD86255C3828039D8C51853\n",
       "  id: 60E6662F04168EEFE781D7ACE576F339\n",
       "  inputFeatureDetails:\n",
       "  - featureType: INTEGER\n",
       "    name: tripduration\n",
       "    orderNumber: 1\n",
       "  - featureType: STRING\n",
       "    name: starttime\n",
       "    orderNumber: 2\n",
       "  - featureType: STRING\n",
       "    name: stoptime\n",
       "    orderNumber: 3\n",
       "  - featureType: FLOAT\n",
       "    name: startstationid\n",
       "    orderNumber: 4\n",
       "  - featureType: FLOAT\n",
       "    name: startstationlatitude\n",
       "    orderNumber: 5\n",
       "  - featureType: FLOAT\n",
       "    name: startstationlongitude\n",
       "    orderNumber: 6\n",
       "  - featureType: FLOAT\n",
       "    name: endstationid\n",
       "    orderNumber: 7\n",
       "  - featureType: FLOAT\n",
       "    name: endstationlatitude\n",
       "    orderNumber: 8\n",
       "  - featureType: FLOAT\n",
       "    name: endstationlongitude\n",
       "    orderNumber: 9\n",
       "  - featureType: INTEGER\n",
       "    name: bikeid\n",
       "    orderNumber: 10\n",
       "  - featureType: STRING\n",
       "    name: usertype\n",
       "    orderNumber: 11\n",
       "  - featureType: INTEGER\n",
       "    name: birthyear\n",
       "    orderNumber: 12\n",
       "  - featureType: INTEGER\n",
       "    name: gender\n",
       "    orderNumber: 13\n",
       "  name: bike_feature_group\n",
       "  primaryKeys:\n",
       "    items:\n",
       "    - name: bikeid\n",
       "  statisticsConfig:\n",
       "    isEnabled: true\n",
       "type: featureGroup"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group_bike.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98afef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DEVELOPER_MODE\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "732e20e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/kshitizlohia/IdeaProjects/oracle/feature-store/advanced-ds/venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/kshitizlohia/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/kshitizlohia/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-e96bd2ce-ad22-46d2-bd46-aa51029113aa;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.3.0 in central\n",
      "\tfound io.delta#delta-storage;2.3.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in local-m2-cache\n",
      ":: resolution report :: resolve 137ms :: artifacts dl 25ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.3.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.3.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from local-m2-cache in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-e96bd2ce-ad22-46d2-bd46-aa51029113aa\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/8ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/16 18:29:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/Users/kshitizlohia/IdeaProjects/oracle/feature-store/advanced-ds/venv/lib/python3.10/site-packages/pyspark/sql/pandas/utils.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pandas.__version__) < LooseVersion(minimum_pandas_version):\n",
      "\n",
      "WARNING:py.warnings:/Users/kshitizlohia/IdeaProjects/oracle/feature-store/advanced-ds/venv/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "\n",
      "WARNING:py.warnings:/Users/kshitizlohia/IdeaProjects/oracle/feature-store/advanced-ds/venv/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "\n",
      "INFO:great_expectations.validator.validator:\t1 expectation(s) included in expectation_suite.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ddfd3353dd457c99630a61d89fe748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/16 18:30:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/05/16 18:30:05 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/05/16 18:30:07 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/16 18:30:11 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/16 18:30:15 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `1c29d0df65e456211b7351d85f271e03`.`bike_feature_group` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "feature_group_bike.materialise(bike_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "711efb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endstationlongitude</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>startstationlongitude</th>\n",
       "      <th>endstationid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>starttime</th>\n",
       "      <th>startstationid</th>\n",
       "      <th>endstationlatitude</th>\n",
       "      <th>startstationlatitude</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>completeness</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approximateNumDistinctValues</th>\n",
       "      <td>83</td>\n",
       "      <td>92</td>\n",
       "      <td>94</td>\n",
       "      <td>83</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>86</td>\n",
       "      <td>36</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataType</th>\n",
       "      <td>Fractional</td>\n",
       "      <td>Integral</td>\n",
       "      <td>Integral</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>String</td>\n",
       "      <td>String</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>Integral</td>\n",
       "      <td>String</td>\n",
       "      <td>Integral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>-7398.150004</td>\n",
       "      <td>76840.0</td>\n",
       "      <td>2914421.0</td>\n",
       "      <td>-7398.157728</td>\n",
       "      <td>155797.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186276.0</td>\n",
       "      <td>4074.01599</td>\n",
       "      <td>4074.092498</td>\n",
       "      <td>198127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-74.016584</td>\n",
       "      <td>97.0</td>\n",
       "      <td>14656.0</td>\n",
       "      <td>-74.012723</td>\n",
       "      <td>127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>40.668603</td>\n",
       "      <td>40.668127</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-73.941995</td>\n",
       "      <td>3494.0</td>\n",
       "      <td>35789.0</td>\n",
       "      <td>-73.942237</td>\n",
       "      <td>3709.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3675.0</td>\n",
       "      <td>40.810792</td>\n",
       "      <td>40.804213</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-73.9815</td>\n",
       "      <td>768.4</td>\n",
       "      <td>29144.21</td>\n",
       "      <td>-73.981577</td>\n",
       "      <td>1557.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1862.76</td>\n",
       "      <td>40.74016</td>\n",
       "      <td>40.740925</td>\n",
       "      <td>1981.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stddev</th>\n",
       "      <td>0.018151</td>\n",
       "      <td>686.187846</td>\n",
       "      <td>6319.234326</td>\n",
       "      <td>0.017465</td>\n",
       "      <td>1428.093551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1438.05532</td>\n",
       "      <td>0.031828</td>\n",
       "      <td>0.03259</td>\n",
       "      <td>11.713117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             endstationlongitude tripduration       bikeid  \\\n",
       "completeness                                 1.0          1.0          1.0   \n",
       "approximateNumDistinctValues                  83           92           94   \n",
       "dataType                              Fractional     Integral     Integral   \n",
       "sum                                 -7398.150004      76840.0    2914421.0   \n",
       "min                                   -74.016584         97.0      14656.0   \n",
       "max                                   -73.941995       3494.0      35789.0   \n",
       "mean                                    -73.9815        768.4     29144.21   \n",
       "stddev                                  0.018151   686.187846  6319.234326   \n",
       "\n",
       "                             startstationlongitude endstationid usertype  \\\n",
       "completeness                                   1.0          1.0      1.0   \n",
       "approximateNumDistinctValues                    83           93        2   \n",
       "dataType                                Fractional   Fractional   String   \n",
       "sum                                   -7398.157728     155797.0      NaN   \n",
       "min                                     -74.012723        127.0      NaN   \n",
       "max                                     -73.942237       3709.0      NaN   \n",
       "mean                                    -73.981577      1557.97      NaN   \n",
       "stddev                                    0.017465  1428.093551      NaN   \n",
       "\n",
       "                             starttime startstationid endstationlatitude  \\\n",
       "completeness                       1.0            1.0                1.0   \n",
       "approximateNumDistinctValues       104             85                 89   \n",
       "dataType                        String     Fractional         Fractional   \n",
       "sum                                NaN       186276.0         4074.01599   \n",
       "min                                NaN           79.0          40.668603   \n",
       "max                                NaN         3675.0          40.810792   \n",
       "mean                               NaN        1862.76           40.74016   \n",
       "stddev                             NaN     1438.05532           0.031828   \n",
       "\n",
       "                             startstationlatitude  birthyear stoptime  \\\n",
       "completeness                                  1.0        1.0      1.0   \n",
       "approximateNumDistinctValues                   86         36      101   \n",
       "dataType                               Fractional   Integral   String   \n",
       "sum                                   4074.092498   198127.0      NaN   \n",
       "min                                     40.668127     1949.0      NaN   \n",
       "max                                     40.804213     1999.0      NaN   \n",
       "mean                                    40.740925    1981.27      NaN   \n",
       "stddev                                    0.03259  11.713117      NaN   \n",
       "\n",
       "                                gender  \n",
       "completeness                       1.0  \n",
       "approximateNumDistinctValues         3  \n",
       "dataType                      Integral  \n",
       "sum                              118.0  \n",
       "min                                0.0  \n",
       "max                                2.0  \n",
       "mean                              1.18  \n",
       "stddev                        0.497594  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group_bike.get_statistics().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a219d096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>success</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results</th>\n",
       "      <td>[{'expectation_config': {'expectation_type': 'expect_column_values_to_not_be_null', 'meta': {}, 'kwargs': {'column': 'stoptime', 'batch_id': 'feca776acdd0aa61ae53da7b674430a1'}}, 'exception_info': {'raised_exception': False, 'exception_traceback': None, 'exception_message': None}, 'result': {'element_count': 100, 'unexpected_count': 0, 'unexpected_percent': 0.0, 'partial_unexpected_list': []}, 'success': True, 'meta': {}}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics.evaluated_expectations</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics.successful_expectations</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics.unsuccessful_expectations</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics.success_percent</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.great_expectations_version</th>\n",
       "      <td>0.16.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.expectation_suite_name</th>\n",
       "      <td>bike_feature_group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.run_id.run_time</th>\n",
       "      <td>2023-05-16T18:29:58.670292+05:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.run_id.run_name</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.batch_markers.ge_load_time</th>\n",
       "      <td>20230516T125958.669418Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.active_batch_definition.datasource_name</th>\n",
       "      <td>feature-ingestion-pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.active_batch_definition.data_connector_name</th>\n",
       "      <td>feature-ingestion-pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.active_batch_definition.data_asset_name</th>\n",
       "      <td>feature-ingestion-pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.active_batch_definition.batch_identifiers.ge_batch_id</th>\n",
       "      <td>8ff83c32-f3e9-11ed-aedd-b29c4acce130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.validation_time</th>\n",
       "      <td>20230516T125958.670193Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta.checkpoint_name</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     0\n",
       "success                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           True\n",
       "results                                                     [{'expectation_config': {'expectation_type': 'expect_column_values_to_not_be_null', 'meta': {}, 'kwargs': {'column': 'stoptime', 'batch_id': 'feca776acdd0aa61ae53da7b674430a1'}}, 'exception_info': {'raised_exception': False, 'exception_traceback': None, 'exception_message': None}, 'result': {'element_count': 100, 'unexpected_count': 0, 'unexpected_percent': 0.0, 'partial_unexpected_list': []}, 'success': True, 'meta': {}}]\n",
       "statistics.evaluated_expectations                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1\n",
       "statistics.successful_expectations                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
       "statistics.unsuccessful_expectations                                                                                                                                                                                                                                                                                                                                                                                                                                                                 0\n",
       "statistics.success_percent                                                                                                                                                                                                                                                                                                                                                                                                                                                                       100.0\n",
       "meta.great_expectations_version                                                                                                                                                                                                                                                                                                                                                                                                                                                                0.16.10\n",
       "meta.expectation_suite_name                                                                                                                                                                                                                                                                                                                                                                                                                                                         bike_feature_group\n",
       "meta.run_id.run_time                                                                                                                                                                                                                                                                                                                                                                                                                                                  2023-05-16T18:29:58.670292+05:30\n",
       "meta.run_id.run_name                                                                                                                                                                                                                                                                                                                                                                                                                                                                              None\n",
       "meta.batch_markers.ge_load_time                                                                                                                                                                                                                                                                                                                                                                                                                                                20230516T125958.669418Z\n",
       "meta.active_batch_definition.datasource_name                                                                                                                                                                                                                                                                                                                                                                                                                                feature-ingestion-pipeline\n",
       "meta.active_batch_definition.data_connector_name                                                                                                                                                                                                                                                                                                                                                                                                                            feature-ingestion-pipeline\n",
       "meta.active_batch_definition.data_asset_name                                                                                                                                                                                                                                                                                                                                                                                                                                feature-ingestion-pipeline\n",
       "meta.active_batch_definition.batch_identifiers.ge_batch_id                                                                                                                                                                                                                                                                                                                                                                                                        8ff83c32-f3e9-11ed-aedd-b29c4acce130\n",
       "meta.validation_time                                                                                                                                                                                                                                                                                                                                                                                                                                                           20230516T125958.670193Z\n",
       "meta.checkpoint_name                                                                                                                                                                                                                                                                                                                                                                                                                                                                              None"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group_bike.get_validation_output_df().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba161c",
   "metadata": {},
   "source": [
    "<a id=\"query_featuregroup\"></a>\n",
    "### 3.4 Query feature group\n",
    "Feature store provides a DataFrame API to ingest data into the Feature Store. You can also retrieve feature data in a DataFrame, that can either be used directly to train models or materialized to file(s) for later use to train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c175849c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------+--------------------+---------------------+------------+------------------+-------------------+------+----------+---------+------+\n",
      "|tripduration|           starttime|            stoptime|startstationid|startstationlatitude|startstationlongitude|endstationid|endstationlatitude|endstationlongitude|bikeid|  usertype|birthyear|gender|\n",
      "+------------+--------------------+--------------------+--------------+--------------------+---------------------+------------+------------------+-------------------+------+----------+---------+------+\n",
      "|         976|2019-01-01 00:15:...|2019-01-01 00:31:...|        3452.0|   40.71915571696044|   -73.94885390996933|       251.0|       40.72317958|       -73.99480012| 35685|Subscriber|     1994|     1|\n",
      "|          97|2019-01-01 00:15:...|2019-01-01 00:17:...|        3430.0|   40.71907891179564|   -73.94223690032959|      3095.0|       40.71929301|       -73.94500379| 34307|Subscriber|     1988|     1|\n",
      "|         467|2019-01-01 00:16:...|2019-01-01 00:24:...|         507.0|         40.73912601|         -73.97973776|       492.0|       40.75019995|       -73.99093085| 35561|Subscriber|     1989|     1|\n",
      "|         348|2019-01-01 00:17:...|2019-01-01 00:23:...|        3095.0|         40.71929301|         -73.94500379|      3101.0|       40.72079821|       -73.95484712| 35695|Subscriber|     1988|     1|\n",
      "|         505|2019-01-01 00:18:...|2019-01-01 00:27:...|        3132.0|         40.76350532|         -73.97109243|       359.0|       40.75510267|       -73.97498696| 31801|Subscriber|     1981|     1|\n",
      "|        3494|2019-01-01 00:18:...|2019-01-01 01:17:...|        3171.0|         40.78524672|         -73.97667321|      3164.0|        40.7770575|       -73.97898475| 35785|Subscriber|     1954|     1|\n",
      "|         829|2019-01-01 00:19:...|2019-01-01 00:32:...|        3165.0|   40.77579376683666|    -73.9762057363987|      3295.0|          40.79127|         -73.964839| 32106|Subscriber|     1969|     0|\n",
      "|         451|2019-01-01 00:21:...|2019-01-01 00:28:...|         403.0|         40.72502876|         -73.99069656|       545.0|         40.736502|       -73.97809472| 32038|Subscriber|     1985|     1|\n",
      "|         736|2019-01-01 00:21:...|2019-01-01 00:33:...|        3165.0|   40.77579376683666|    -73.9762057363987|      3295.0|          40.79127|         -73.964839| 16761|  Customer|     1989|     2|\n",
      "|         617|2019-01-01 00:21:...|2019-01-01 00:31:...|        3159.0|         40.77492513|         -73.98266566|      3142.0|        40.7612274|       -73.96094022| 24895|Subscriber|     1998|     1|\n",
      "+------------+--------------------+--------------------+--------------+--------------------+---------------------+------------+------------------+-------------------+------+----------+---------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = feature_group_bike.select() \n",
    "query.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e563d",
   "metadata": {},
   "source": [
    "<a id=\"create_dataset\"></a>\n",
    "### 3.5 Create dataset\n",
    "A dataset is a collection of feature snapshots that are joined together to either train a model or perform model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "147ae5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT fg_0.tripduration tripduration, fg_0.starttime starttime, fg_0.stoptime stoptime, fg_0.startstationid startstationid, fg_0.startstationlatitude startstationlatitude, fg_0.startstationlongitude startstationlongitude, fg_0.endstationid endstationid, fg_0.endstationlatitude endstationlatitude, fg_0.endstationlongitude endstationlongitude, fg_0.bikeid bikeid, fg_0.usertype usertype, fg_0.birthyear birthyear, fg_0.gender gender FROM `1C29D0DF65E456211B7351D85F271E03`.bike_feature_group fg_0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "440b129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_resource = (\n",
    "    Dataset()\n",
    "    .with_description(\"Dataset consisting of a subset of features in feature group: bike riders\")\n",
    "    .with_compartment_id(compartment_id)\n",
    "    .with_name(\"bike_riders_dataset\")\n",
    "    .with_entity_id(entity.id)\n",
    "    .with_feature_store_id(feature_store.id)\n",
    "    .with_query(query.to_string())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10dd5758",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_resource.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4b077da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/16 18:31:37 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table `1c29d0df65e456211b7351d85f271e03`.`bike_riders_dataset` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dataset.materialise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db5d6854",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdataset\u001B[49m\u001B[38;5;241m.\u001B[39mget_statistics()\u001B[38;5;241m.\u001B[39mto_pandas()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset.get_statistics().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38da2a60",
   "metadata": {},
   "source": [
    "<a id=\"featurestore_yaml\"></a>\n",
    "# 4. Feature store quick start using YAML\n",
    "In an ADS feature store module, you can either use the Python programmatic interface or YAML to define feature store entities. Below section describes how to create feature store entities using YAML as an interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3aa939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_yaml = \"\"\"\n",
    "apiVersion: v1\n",
    "kind: featureStore\n",
    "spec:\n",
    "  displayName: Bike feature store\n",
    "  compartmentId: \"ocid1.tenancy.oc1..aaaaaaaa462hfhplpx652b32ix62xrdijppq2c7okwcqjlgrbknhgtj2kofa\"\n",
    "  offlineConfig:\n",
    "    metastoreId: \"ocid1.datacatalogmetastore.oc1.iad.amaaaaaabiudgxyap7tizm4gscwz7amu7dixz7ml3mtesqzzwwg3urvvdgua\"\n",
    "\n",
    "  entity: &bike_entity\n",
    "    - kind: entity\n",
    "      spec:\n",
    "        name: Bike rides\n",
    "\n",
    "  featureGroup:\n",
    "    - kind: featureGroup\n",
    "      spec:\n",
    "        entity: *bike_entity\n",
    "        name: bike_feature_group\n",
    "        primaryKeys:\n",
    "          - bikeid\n",
    "        inputFeatureDetails:\n",
    "          - name: \"bikeid\"\n",
    "            featureType: \"INTEGER\"\n",
    "            orderNumber: 1\n",
    "            cast: \"STRING\"\n",
    "          - name: \"endstationlongitude\"\n",
    "            featureType: \"FLOAT\"\n",
    "            orderNumber: 2\n",
    "            cast: \"STRING\"\n",
    "          - name: \"tripduration\"\n",
    "            featureType: \"INTEGER\"\n",
    "            orderNumber: 3\n",
    "            cast: \"STRING\"\n",
    "\n",
    "  dataset:\n",
    "    - kind: dataset\n",
    "      spec:\n",
    "        name: bike_dataset\n",
    "        entity: *bike_entity\n",
    "        description: \"Dataset for bike\"\n",
    "        query: 'SELECT bike.bikeid, bike.endstationlongitude FROM bike_feature_group bike'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "238a8507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75021638e00044e09f9dfa4e15aa6ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created 1 entities, 0 transformations, 1 feature groups and 1 datasets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(kind: featurestore\n",
       " spec:\n",
       "   compartmentId: ocid1.tenancy.oc1..aaaaaaaa462hfhplpx652b32ix62xrdijppq2c7okwcqjlgrbknhgtj2kofa\n",
       "   dataset:\n",
       "   - kind: dataset\n",
       "     spec:\n",
       "       description: Dataset for bike\n",
       "       entity: &id001\n",
       "       - kind: entity\n",
       "         spec:\n",
       "           name: Bike rides\n",
       "       name: bike_dataset\n",
       "       query: SELECT bike.bikeid, bike.endstationlongitude FROM bike_feature_group\n",
       "         bike\n",
       "   displayName: Bike feature store\n",
       "   entity: *id001\n",
       "   featureGroup:\n",
       "   - kind: featureGroup\n",
       "     spec:\n",
       "       entity: *id001\n",
       "       inputFeatureDetails:\n",
       "       - cast: STRING\n",
       "         featureType: INTEGER\n",
       "         name: bikeid\n",
       "         orderNumber: 1\n",
       "       - cast: STRING\n",
       "         featureType: FLOAT\n",
       "         name: endstationlongitude\n",
       "         orderNumber: 2\n",
       "       - cast: STRING\n",
       "         featureType: INTEGER\n",
       "         name: tripduration\n",
       "         orderNumber: 3\n",
       "       name: bike_feature_group\n",
       "       primaryKeys:\n",
       "       - bikeid\n",
       "   id: A66AAEF30860DEDFC0635EF806CCBD9E\n",
       "   offlineConfig:\n",
       "     metastoreId: ocid1.datacatalogmetastore.oc1.iad.amaaaaaabiudgxyap7tizm4gscwz7amu7dixz7ml3mtesqzzwwg3urvvdgua\n",
       " type: featureStore,\n",
       " [kind: entity\n",
       "  spec:\n",
       "    compartmentId: ocid1.tenancy.oc1..aaaaaaaa462hfhplpx652b32ix62xrdijppq2c7okwcqjlgrbknhgtj2kofa\n",
       "    featureStoreId: A66AAEF30860DEDFC0635EF806CCBD9E\n",
       "    id: 36FD1B1F869261D46CF1AF1A297BAF6A\n",
       "    name: Bike rides\n",
       "  type: entity],\n",
       " [],\n",
       " [kind: FeatureGroup\n",
       "  spec:\n",
       "    compartmentId: ocid1.tenancy.oc1..aaaaaaaa462hfhplpx652b32ix62xrdijppq2c7okwcqjlgrbknhgtj2kofa\n",
       "    entity:\n",
       "    - kind: entity\n",
       "      spec:\n",
       "        name: Bike rides\n",
       "    entityId: 36FD1B1F869261D46CF1AF1A297BAF6A\n",
       "    featureStoreId: A66AAEF30860DEDFC0635EF806CCBD9E\n",
       "    id: F8C723AC26F9D025415FB150F4F5BAEB\n",
       "    inputFeatureDetails:\n",
       "    - cast: STRING\n",
       "      featureType: INTEGER\n",
       "      name: bikeid\n",
       "      orderNumber: 1\n",
       "    - cast: STRING\n",
       "      featureType: FLOAT\n",
       "      name: endstationlongitude\n",
       "      orderNumber: 2\n",
       "    - cast: STRING\n",
       "      featureType: INTEGER\n",
       "      name: tripduration\n",
       "      orderNumber: 3\n",
       "    name: bike_feature_group\n",
       "    primaryKeys:\n",
       "      items:\n",
       "      - name: bikeid\n",
       "    statisticsConfig:\n",
       "      isEnabled: true\n",
       "  type: featureGroup],\n",
       " [kind: Dataset\n",
       "  spec:\n",
       "    compartmentId: ocid1.tenancy.oc1..aaaaaaaa462hfhplpx652b32ix62xrdijppq2c7okwcqjlgrbknhgtj2kofa\n",
       "    description: Dataset for bike\n",
       "    entity:\n",
       "    - kind: entity\n",
       "      spec:\n",
       "        name: Bike rides\n",
       "    entityId: 36FD1B1F869261D46CF1AF1A297BAF6A\n",
       "    featureStoreId: A66AAEF30860DEDFC0635EF806CCBD9E\n",
       "    id: B72896BC833BAB23EA24A27CC99B718A\n",
       "    name: bike_dataset\n",
       "    query: SELECT bike.bikeid, bike.endstationlongitude FROM bike_feature_group bike\n",
       "    statisticsConfig:\n",
       "      isEnabled: true\n",
       "  type: dataset])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registrar = FeatureStoreRegistrar.from_yaml(yaml_string=feature_store_yaml)\n",
    "registrar.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eae605",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "# References\n",
    "\n",
    "- [ADS Library Documentation](https://accelerated-data-science.readthedocs.io/en/latest/index.html)\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
