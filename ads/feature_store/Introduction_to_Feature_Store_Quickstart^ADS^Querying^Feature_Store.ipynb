{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "@notebook{feature_store-quickstart.ipynb,\n",
    "    title: Using feature store for feature ingestion and feature querying,\n",
    "    summary: Feature store quickstart guide to perform feature ingestion and feature querying.,\n",
    "    developed_on: pyspark32_p38_cpu_feature_store_v1,\n",
    "    keywords: feature store,\n",
    "    license: Universal Permissive License v 1.0\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Upgrade Oracle ADS to pick up the latest preview version to maintain compatibility with Oracle Cloud Infrastructure.\n",
    "\n",
    "!odsc conda install --uri https://objectstorage.us-ashburn-1.oraclecloud.com/p/qnzzHQPGQYghdyH206yDk25MZH1FaMGdNNhKUl74BhRsW4muvFyGViKIqpxgnxI3/n/ociodscdev/b/ads_conda_pack_builds/o/PySpark_3/teamcity_20230512_084146_38972446/f227145b7ee5fc1c73a69ebaa671b81e/PySpark_3.2_and_Feature_Store.tar.gz"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Oracle Data Science service sample notebook.\n",
    "\n",
    "Copyright (c) 2022 Oracle, Inc. All rights reserved. Licensed under the [Universal Permissive License v 1.0](https://oss.oracle.com/licenses/upl).\n",
    "\n",
    "***\n",
    "\n",
    "# <font color=\"red\">Feature store quickstart</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=\"teal\">Oracle Cloud Infrastructure Data Science Service.</font></p>\n",
    "\n",
    "---\n",
    "# Overview:\n",
    "---\n",
    "Managing many datasets, data-sources and transformations for machine learning is complex and costly. Poorly cleaned data, data issues, bugs in transformations, data drift and training serving skew all leads to increased model development time and worse model performance. Here, feature store is well positioned to solve many of the problems since it provides a centralised way to transform and access data for training and serving time and helps defines a standardised pipeline for ingestion of data and querying of data.\n",
    "\n",
    "## Contents:\n",
    "\n",
    "- <a href=\"#concepts\">1. Introduction</a>\n",
    "- <a href='#pre-requisites'>2. Pre-requisites</a>\n",
    "    - <a href='#policies'>2.1 Policies</a>\n",
    "    - <a href='#prerequisites_authentication'>2.2 Authentication</a>\n",
    "    - <a href='#prerequisites_variables'>2.3 Variables</a>\n",
    "- <a href='#featurestore_overview'>3. Feature store quickstart using APIs</a>\n",
    "    - <a href='#create_featurestore'>3.1. Create feature store</a>\n",
    "    - <a href='#create_entity'>3.2. Create business entity in feature store</a>\n",
    "    - <a href='#create_featuregroup'>3.3. Create feature group and upload data to feature group</a>\n",
    "    - <a href='#query_featuregroup'>3.4. Query feature group</a>\n",
    "    - <a href='#create_dataset'>3.5. Create dataset from multiple or one feature group</a>\n",
    "    - <a href='#query_dataset'>3.6 Query dataset</a>\n",
    "- <a href='#featurestore_yaml'>4. Feature store quickstart using YAML</a>\n",
    "- <a href='#ref'>5. References</a>\n",
    "\n",
    "---\n",
    "\n",
    "**Important:**\n",
    "\n",
    "Placeholder text for required values are surrounded by angle brackets that must be removed when adding the indicated content. For example, when adding a database name to `database_name = \"<database_name>\"` would become `database_name = \"production\"`.\n",
    "\n",
    "---\n",
    "\n",
    "Datasets are provided as a convenience.  Datasets are considered third-party content and are not considered materials under your agreement with Oracle.\n",
    "\n",
    "This [`Citi Bike`](https://ride.citibikenyc.com/data-sharing-policy) dataset license is used in this notebook.\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"concepts\"></a>\n",
    "# 1. Introduction\n",
    "\n",
    "Oracle feature store is a stack based solution that is deployed in the customer enclave using OCI resource manager. Customer can stand up the service with infrastructure in their own tenancy. The service consists of API which are deployed in customer tenancy using resource manager.\n",
    "\n",
    "The following are some key terms that will help you understand OCI Data Science Feature Store:\n",
    "\n",
    "\n",
    "* **Feature Vector**: Set of feature values for any one primary/identifier key. Eg.  All/subset of  features of customer id '2536' can be called as one feature vector.\n",
    "* **Feature**: A feature is an individual measurable property or characteristic of a phenomenon being observed.\n",
    "* **Entity**: An entity is a group of semantically related features.\n",
    "* **Datasource**: Features are engineered from raw data stored in various data sources (e.g. object storage, Oracle Database, Oracle MySQL, etc).\n",
    "* **Feature Group** - A feature group is an object that represents a logical group of time-series feature data as it is found in a datasource.\n",
    "* **Dataset**: Datasets are created from features stored in the feature store service and are used to train models and to perform online model inference."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "ce2f00ee",
   "metadata": {},
   "source": [
    "<a id='pre-requisites'></a>\n",
    "# 2. Pre-requisites\n",
    "\n",
    "Notebook Sessions are accessible through the following conda environment: \n",
    "\n",
    "* **PySpark 3.2 and Feature store 1.0 (pyspark32_p38_cpu_feature_store_v1)**\n",
    "\n",
    "You can customize `pyspark32_p38_cpu_feature_store_v1`, publish it, and use it as a runtime environment for a Notebook session cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a781306",
   "metadata": {},
   "source": [
    "<a id='policies'></a>\n",
    "### 2.1. Policies\n",
    "This section covers the creation of dynamic groups and policies needed to use the service.\n",
    "\n",
    "* [About Data Science Policies](https://docs.oracle.com/iaas/data-science/using/policies.htm)\n",
    "* [Data Catalog Metastore Required Policies](https://docs.oracle.com/en-us/iaas/data-catalog/using/metastore.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7106e4",
   "metadata": {},
   "source": [
    "<a id=\"prerequisites_authentication\"></a>\n",
    "### 2.2. Authentication\n",
    "The [Oracle Accelerated Data Science SDK (ADS)](https://docs.oracle.com/iaas/tools/ads-sdk/latest/index.html) controls the authentication mechanism with the notebook Spark cluster.<br> \n",
    "To setup authentication use the ```ads.set_auth(\"resource_principal\")``` or ```ads.set_auth(\"api_key\")```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdc3aa",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import ads\n",
    "ads.set_auth(auth=\"api_key\", client_kwargs={\"service_endpoint\": \"http://localhost:21000/20230101\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c223c0",
   "metadata": {},
   "source": [
    "<a id=\"prerequisites_variables\"></a>\n",
    "### 2.3. Variables\n",
    "To run this notebook, you must provide some information about your tenancy configuration. To create and run a feature store, you must specify a `<compartment_id>` and bucket `<metastore_id>` for storing logs. The [Data Catalog Hive Metastore](https://docs.oracle.com/en-us/iaas/data-catalog/using/metastore.htm) provides schema definitions for objects in structured and unstructured data assets. The Metastore is the central metadata repository to understand tables backed by files on object storage and the metastore id of hive metastore is tied to feature store construct of feature store service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ca06cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "compartment_id = os.environ.get(\"NB_SESSION_COMPARTMENT_OCID\")\n",
    "metastore_id = \"<metastore_id>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc9e2c",
   "metadata": {},
   "source": [
    "<a id=\"featurestore_overview\"></a>\n",
    "# 3. Feature store quick start using APIs\n",
    "By default the **PySpark 3.2, Feature store and Data Flow** conda environment includes pre-installed [great-expectations](https://legacy.docs.greatexpectations.io/en/latest/reference/core_concepts/validation.html) and [deeque](https://github.com/awslabs/deequ) libraries. In an ADS feature store module, you can either use the Python programmatic or YAML interface to define feature store entities. Below section describes how to create feature store entities using programmatic interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bfeace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from ads.feature_store.feature_store import FeatureStore\n",
    "from ads.feature_store.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3fad36",
   "metadata": {},
   "source": [
    "<a id=\"create_featurestore\"></a>\n",
    "### 3.1 Create feature store\n",
    "Feature store is a top level construct to provide logical segregation of resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_resource = FeatureStore().\\\n",
    "    with_description(\"Data consisting of bike riders data\").\\\n",
    "    with_compartment_id(compartment_id).\\\n",
    "    with_display_name(\"Bike rides\").\\\n",
    "    with_offline_config(metastore_id=metastore_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191d1d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store = feature_store_resource.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba52241",
   "metadata": {},
   "source": [
    "<a id=\"create_entity\"></a>\n",
    "### 3.2 Create entity\n",
    "An entity is a group of semantically related features. The first step a consumer of features would typically do when accessing the feature store service is to list the entities and the entities associated features. Another way to look at it is that an entity is an object or concept that is described by its features. Examples of entities could be customer, product, transaction, review, image, document, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fff48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = feature_store.create_entity(\n",
    "    display_name=\"Bike rides\",\n",
    "    description=\"description for bike riders\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d165b",
   "metadata": {},
   "source": [
    "<a id=\"create_featuregroup\"></a>\n",
    "### 3.3 Create feature group\n",
    "A feature group is the code that contains instructions on the ingestion of raw data and computation of the feature. This [`Citi Bike`](https://ride.citibikenyc.com/data-sharing-policy) dataset license is used in this notebook. values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a8dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ads.feature_store.feature_group import FeatureGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = FeatureGroup.with_primary_keys([\"ride_id\"])\\\n",
    "    .with_display_name(\"city_bike_feature_group\")\\\n",
    "    .with_entity_id(entity.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a76370",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_df = pd.read_csv(\"/data/biketrips/JC-201901-citibike-tripdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group.materialise(profiles_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba161c",
   "metadata": {},
   "source": [
    "<a id=\"query_featuregroup\"></a>\n",
    "### 3.4 Query feature group\n",
    "Feature store provides a DataFrame API to ingest data into the Feature Store. You can also retrieve feature data in a DataFrame, that can either be used directly to train models or materialized to file(s) for later use to train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = feature_group.select([\"ride_id\",\"rideable_type\"]) \n",
    "query.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e563d",
   "metadata": {},
   "source": [
    "<a id=\"create_dataset\"></a>\n",
    "### 3.5 Create dataset\n",
    "A dataset is a collection of feature snapshots that are joined together to either train a model or perform model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_resource = Dataset()\\\n",
    "    .with_description(\"Dataset consisting of a subset of features in feature group: bike riders\")\\\n",
    "    .with_compartment_id(compartment_id)\\\n",
    "    .with_name(\"Bike riders dataset\")\\\n",
    "    .with_entity_id(entity.id)\\\n",
    "    .with_feature_store_id(feature_store.id)\\\n",
    "    .with_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd5758",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_resource.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b077da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.materialise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e2698",
   "metadata": {},
   "source": [
    "<a id=\"query_dataset\"></a>\n",
    "### 3.6 Query dataset\n",
    "Feature store provides a DataFrame API to ingest data into the Feature Store. You can also retrieve feature data in a DataFrame, that can either be used directly to train models or materialized to file(s) for later use to train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba978a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dataset.select([\"ride_id\",\"rideable_type\"]) \n",
    "query.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"featurestore_yaml\"></a>\n",
    "# 4. Feature store quick start using YAML\n",
    "In an ADS feature store module, you can either use the Python programmatic interface or YAML to define feature store entities. Below section describes how to create feature store entities using YAML as an interface."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ads.feature_store.feature_store_registrar import FeatureStoreRegistrar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "37eae605",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "# References\n",
    "\n",
    "- [ADS Library Documentation](https://accelerated-data-science.readthedocs.io/en/latest/index.html)\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
