{
  "inference_params": {
    "default": {
      "inference_backoff_factor": 3.0,
      "inference_delay": 0.0,
      "inference_max_threads": 10,
      "inference_retries": 3,
      "inference_rps": 25,
      "inference_timeout": 120
    },
    "frameworks": [
      {
        "framework": "vllm",
        "params": {}
      },
      {
        "framework": "tgi",
        "params": {}
      },
      {
        "framework": "llama-cpp",
        "params": {
          "inference_delay": 1,
          "inference_max_threads": 1
        }
      }
    ]
  },
  "kind": "evaluation",
  "metrics": [
    {
      "args": {},
      "description": "BERT Score.",
      "key": "bertscore",
      "name": "BERT Score",
      "tags": [],
      "task": [
        "text-generation"
      ]
    },
    {
      "args": {},
      "description": "ROUGE scores.",
      "key": "rouge",
      "name": "ROUGE Score",
      "tags": [],
      "task": [
        "text-generation"
      ]
    },
    {
      "args": {},
      "description": "BLEU (Bilingual Evaluation Understudy).",
      "key": "bleu",
      "name": "BLEU Score",
      "tags": [],
      "task": [
        "text-generation"
      ]
    },
    {
      "args": {},
      "description": "Perplexity is a metric to evaluate the quality of language models.",
      "key": "perplexity_score",
      "name": "Perplexity Score",
      "tags": [],
      "task": [
        "text-generation"
      ]
    },
    {
      "args": {},
      "description": "Text quality/readability metrics.",
      "key": "text_readability",
      "name": "Text Readability",
      "tags": [],
      "task": [
        "text-generation"
      ]
    }
  ],
  "model_params": {
    "default": {
      "some_default_param": "some_default_param"
    },
    "frameworks": [
      {
        "default": {
          "add_generation_prompt": false,
          "frequency_penalty": {
            "default": 0.0,
            "max": 2.0,
            "min": -2.0
          },
          "max_tokens": {
            "default": 500,
            "max": 4096,
            "min": 50
          },
          "model": "odsc-llm",
          "presence_penalty": {
            "default": 0.0,
            "max": 2.0,
            "min": -2.0
          },
          "stop": [],
          "temperature": {
            "default": 0.7,
            "max": 2.0,
            "min": 0.0
          },
          "top_k": {
            "default": 50,
            "max": 1000,
            "min": 1
          },
          "top_p": {
            "default": 0.9,
            "max": 1.0,
            "min": 0.0
          }
        },
        "framework": "vllm",
        "task": [
          "text-generation",
          "image-text-to-text"
        ],
        "versions": {
          "0.5.1": {
            "overrides": {
              "exclude": [
                "max_tokens",
                "frequency_penalty"
              ],
              "include": {
                "some_other_param": "some_other_param_value"
              }
            }
          },
          "0.5.3.post1": {
            "overrides": {
              "exclude": [
                "add_generation_prompt"
              ],
              "include": {}
            }
          }
        }
      },
      {
        "default": {
          "add_generation_prompt": false,
          "frequency_penalty": {
            "default": 0.0,
            "max": 2.0,
            "min": -2.0
          },
          "max_tokens": {
            "default": 500,
            "max": 4096,
            "min": 50
          },
          "model": "odsc-llm",
          "presence_penalty": {
            "default": 0.0,
            "max": 2.0,
            "min": -2.0
          },
          "stop": [],
          "temperature": {
            "default": 0.7,
            "max": 2.0,
            "min": 0.0
          },
          "top_k": {
            "default": 50,
            "max": 1000,
            "min": 1
          },
          "top_p": {
            "default": 0.9,
            "max": 1.0,
            "min": 0.0
          }
        },
        "framework": "tgi",
        "task": [
          "text-generation",
          "image-text-to-text"
        ],
        "versions": {
          "2.0.1.4": {
            "overrides": {
              "exclude": [
                "max_tokens",
                "frequency_penalty"
              ],
              "include": {
                "some_other_param": "some_other_param_value"
              }
            }
          }
        }
      },
      {
        "default": {
          "add_generation_prompt": false,
          "frequency_penalty": {
            "default": 0.0,
            "max": 2.0,
            "min": -2.0
          },
          "max_tokens": {
            "default": 500,
            "max": 4096,
            "min": 50
          },
          "model": "odsc-llm",
          "presence_penalty": {
            "default": 0.0,
            "max": 2.0,
            "min": -2.0
          },
          "stop": [],
          "temperature": {
            "default": 0.7,
            "max": 2.0,
            "min": 0.0
          },
          "top_k": {
            "default": 50,
            "max": 1000,
            "min": 1
          },
          "top_p": {
            "default": 0.9,
            "max": 1.0,
            "min": 0.0
          }
        },
        "framework": "llama-cpp",
        "task": [
          "text-generation",
          "image-text-to-text"
        ],
        "versions": {
          "0.2.78.0": {
            "overrides": {
              "exclude": [],
              "include": {}
            }
          }
        }
      }
    ]
  },
  "report_params": {
    "default": {}
  },
  "shapes": [
    {
      "block_storage_size": 200,
      "filter": {
        "evaluation_container": [
          "odsc-llm-evaluate"
        ],
        "evaluation_target": [
          "datasciencemodeldeployment"
        ]
      },
      "memory_in_gbs": 128,
      "name": "VM.Standard.E3.Flex",
      "ocpu": 8
    },
    {
      "block_storage_size": 200,
      "filter": {
        "evaluation_container": [
          "odsc-llm-evaluate"
        ],
        "evaluation_target": [
          "datasciencemodeldeployment"
        ]
      },
      "memory_in_gbs": 128,
      "name": "VM.Standard.E4.Flex",
      "ocpu": 8
    },
    {
      "block_storage_size": 200,
      "filter": {
        "evaluation_container": [
          "odsc-llm-evaluate"
        ],
        "evaluation_target": [
          "datasciencemodeldeployment"
        ]
      },
      "memory_in_gbs": 128,
      "name": "VM.Standard3.Flex",
      "ocpu": 8
    },
    {
      "block_storage_size": 200,
      "filter": {
        "evaluation_container": [
          "odsc-llm-evaluate"
        ],
        "evaluation_target": [
          "datasciencemodeldeployment"
        ]
      },
      "memory_in_gbs": 128,
      "name": "VM.Optimized3.Flex",
      "ocpu": 8
    },
    {
      "block_storage_size": 200,
      "filter": {
        "evaluation_container": [
          "odsc-llm-evaluate"
        ],
        "evaluation_target": [
          "datasciencemodel"
        ]
      },
      "memory_in_gbs": null,
      "name": "VM.GPU.A10.2",
      "ocpu": null
    }
  ],
  "version": "1.0"
}
